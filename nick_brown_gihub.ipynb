{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import bs4 as bs\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "import tldextract\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scrapping url\n",
    "scrapping_url = \"https://github.com/nikbearbrown/Deep_Learning\"\n",
    "scrapping_page = urllib.request.urlopen(scrapping_url)\n",
    "\n",
    "soup = bs.BeautifulSoup(scrapping_page,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "#print(soup.title.text,now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#our variables\n",
    "anchor_index = 1\n",
    "external_links = []\n",
    "coulumn_labels = ['Link description', 'URL', 'is valid?', 'TimeStamp','Error Details']\n",
    "get_desc = lambda s: None if s==None else s.strip()\n",
    "#domain name of our scrapping url\n",
    "master_domain = tldextract.extract(scrapping_url).domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://research.microsoft.com/pubs/209355/DeepLearning-NowPublishing-Vol7-SIG-039.pdf\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "\n",
      "http://vision.stanford.edu/teaching/cs231n/syllabus_winter2015.html\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://www.bayareadlschool.org/\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "http://web.stanford.edu/class/cs224n/handouts/\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://www.nature.com/nature/journal/v529/n7587/pdf/nature16961.pdf\n",
      "HTTP Error 401: Unauthorized\n",
      "\n",
      "\n",
      "http://www.ai.sri.com/\n",
      "<urlopen error [Errno 11] Resource temporarily unavailable>\n",
      "\n",
      "\n",
      "http://www.isi.edu/AI/isd.htm\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "\n",
      "https://medium.com/@ageitgey/\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "\n",
      "http://shannon.cs.illinois.edu/DenotationGraph/\n",
      "<urlopen error [Errno 11] Resource temporarily unavailable>\n",
      "\n",
      "\n",
      "http://www.uk.research.att.com/facedatabase.html\n",
      "<urlopen error [Errno -5] No address associated with hostname>\n",
      "\n",
      "\n",
      "http://xtreme.gsfc.nasa.gov\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "http://www.science.uva.nl/%7Ealoi/\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://www.cog.brown.edu/%7Etarr/stimuli.html\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://www.cs.waikato.ac.nz/%7Esinglis/ccitt.html\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://www.ri.cmu.edu/projects/project_418.html\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://www.ius.cs.cmu.edu/idb/\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "http://www.cs.columbia.edu/CAVE/curet/\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://ls7-www.cs.uni-dortmund.de/%7Epeters/pages/research/modeladaptsys/modeladaptsys_vba_rov.html\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://vision.psych.umn.edu/www/kersten-lab/kersten-lab.html\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://sting.cycollege.ac.cy/%7Ealanitis/fgnetaging/index.htm\n",
      "<urlopen error [Errno 11] Resource temporarily unavailable>\n",
      "\n",
      "\n",
      "http://bias.csr.unibo.it/research/biolab\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://hlab.phys.rug.nl/archive.html\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "http://www.ien.it/is/vislib/\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "http://www-rocq.inria.fr/%7Etarel/syntim/images.html\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://www-rocq.inria.fr/%7Etarel/syntim/paires.html\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://www.prip.tuwien.ac.at/prip/image.html\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://www.mis.atr.co.jp/%7Emlyons/jaffe.html\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "http://www.mic.atr.co.jp/\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "http://www-white.media.mit.edu/vismod/imagery/VisionTexture/vistex.html\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "http://vision.cse.psu.edu/book/testbed/images/\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "ftp://ftp.cps.msu.edu/pub/prip\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "http://www.middlebury.edu/stereo/data.html\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://www.middlebury.edu/stereo\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://ltpwww.gsfc.nasa.gov/MODIS/MAS/\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "http://gicl.mcs.drexel.edu\n",
      "<urlopen error [Errno -2] Name or service not known>\n",
      "\n",
      "\n",
      "http://eewww.eng.ohio-state.edu/%7Eflynn/3DDB/Models/\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://eewww.eng.ohio-state.edu/%7Eflynn/3DDB/RID/\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://sampl.eng.ohio-state.edu/%7Esampl/database.htm\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "http://www.cs.otago.ac.nz/research/vision/Research/OpticalFlow/opticalflow.html\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "\n",
      "ftp://ftp.limsi.fr/pub/quenot/opflow/testdata/piv/\n",
      "<urlopen error ftp error: error_perm('530 Login authentication failed',)>\n",
      "\n",
      "\n",
      "http://www.limsi.fr/Recherche/IMM/PageIMM.html\n",
      "<urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#find all anchor 'a' tags\n",
    "for anchor in soup.find_all('a'):\n",
    "    href_link = anchor['href']\n",
    "    #extract url details using tldextract\n",
    "    url_domain = tldextract.extract(href_link).domain\n",
    "    \n",
    "    # if the url domain is same or blank, it means the link is internal(belongs to same domain)\n",
    "    if(url_domain != master_domain and url_domain != \"\"):\n",
    "\n",
    "        is_url_valid = True\n",
    "        try:\n",
    "            urllib.request.urlopen(href_link)\n",
    "        except Exception as e:\n",
    "            is_url_valid = False\n",
    "            print(href_link)\n",
    "            print(e)\n",
    "            print('\\n')\n",
    "            external_links.append((get_desc(anchor.string),href_link,is_url_valid,now,e))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link description</th>\n",
       "      <th>URL</th>\n",
       "      <th>is valid?</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Error Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Link description, URL, is valid?, TimeStamp, Error Details]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(external_links, columns=coulumn_labels)\n",
    "writer = pd.ExcelWriter('Deep_Learning_Failed_links.xlsx', engine='xlsxwriter')\n",
    "\n",
    "\n",
    "df.to_excel(writer, sheet_name='Sheet1')\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
